# main.py - Actualizado para Kaggle Hub

import pandas as pd
import os
import sys

# A√±adir el directorio ra√≠z al path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.loader import DataLoader
from data.preprocessor import DataPreprocessor
from data.explorer import DataExplorer
from models.trainer import ModelTrainer
from models.evaluator import ModelEvaluator
from config import MODEL_SAVE_PATH, PLOT_SAVE_PATH, DATASET_SOURCES

def main():
    """Funci√≥n principal que ejecuta el pipeline completo"""
    print("ü©∫ INICIANDO SISTEMA DE PREDICCI√ìN DE DIABETES")
    print("=" * 50)
    
    # Paso 1: Cargar datos desde Kaggle Hub
    print("\n1Ô∏è‚É£  CARGANDO DATOS DESDE KAGGLE HUB...")
    loader = DataLoader()
    
    # Intentar cargar desde Kaggle, con fallback a URL
    df = loader.load_data(source='kaggle')
    
    if df is None:
        print("‚ùå Error: No se pudieron cargar los datos")
        return
    
    # Guardar copia local para futuras ejecuciones
    loader.save_local_copy()
    
    # Mostrar informaci√≥n del dataset
    info = loader.get_data_info()
    print(f"üìä Dataset cargado: {info['shape'][0]} registros, {info['shape'][1]} caracter√≠sticas")
    print(f"üìÅ Fuente: {info['source_path']}")
    
    # Paso 2: An√°lisis exploratorio
    print("\n2Ô∏è‚É£  AN√ÅLISIS EXPLORATORIO...")
    explorer = DataExplorer(df)
    report = explorer.generate_summary_report()
    
    # Paso 3: Preprocesamiento
    print("\n3Ô∏è‚É£  PREPROCESAMIENTO DE DATOS...")
    preprocessor = DataPreprocessor()
    splits = preprocessor.preprocess(df)
    
    # Resto del c√≥digo se mantiene igual...
    # Paso 4: Entrenamiento de modelos
    print("\n4Ô∏è‚É£  ENTRENAMIENTO DE MODELOS...")
    trainer = ModelTrainer()
    trainer.initialize_models()
    training_results = trainer.train_models(splits)
    
    # Mostrar resumen del entrenamiento
    summary = trainer.get_training_summary()
    print("\nüìä RESUMEN DEL ENTRENAMIENTO:")
    print(summary.to_string(index=False))
    
    # Paso 5: Evaluaci√≥n de modelos
    print("\n5Ô∏è‚É£  EVALUACI√ìN DE MODELOS...")
    evaluator = ModelEvaluator(training_results, splits)
    test_results = evaluator.evaluate_on_test()
    
    # Generar reportes comparativos
    comparison_df = evaluator.generate_comparison_report()
    print("\nüìà COMPARACI√ìN EN CONJUNTO DE PRUEBA:")
    print(comparison_df.to_string(index=False))
    
    # Generar gr√°ficos de evaluaci√≥n
    evaluator.plot_confusion_matrices()
    evaluator.plot_roc_curves()
    evaluator.plot_metrics_comparison()
    
    # Paso 6: Guardar modelos
    print("\n6Ô∏è‚É£  GUARDANDO MODELOS...")
    trainer.save_models()
    
    # Paso 7: Resumen final
    print("\n" + "=" * 50)
    print("üéâ PIPELINE COMPLETADO EXITOSAMENTE")
    print("=" * 50)
    
    best_model_test = comparison_df.loc[comparison_df['AUC-ROC'].idxmax()]
    print(f"üèÜ MEJOR MODELO: {best_model_test['Modelo']}")
    print(f"üìä M√âTRICAS EN TEST:")
    print(f"   - AUC-ROC: {best_model_test['AUC-ROC']}")
    print(f"   - Accuracy: {best_model_test['Accuracy']}")
    print(f"   - F1-Score: {best_model_test['F1-Score']}")
    
    print(f"\nüíæ Modelos guardados en: {MODEL_SAVE_PATH}")
    print(f"üìä Gr√°ficos guardados en: {PLOT_SAVE_PATH}")

if __name__ == "__main__":
    main()